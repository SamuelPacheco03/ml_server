# ML Server - API Backend para Modelos de Machine Learning

API backend completa construida con Node.js, Express y TypeScript para ejecutar modelos de machine learning ONNX en producciÃ³n.

## ğŸš€ CaracterÃ­sticas

- **Arquitectura en capas**: Routes, Controllers, Services
- **TypeScript**: CÃ³digo tipado y seguro
- **ValidaciÃ³n de datos**: Usando Zod para validar payloads
- **Manejo de errores centralizado**: Middlewares para errores y rutas no encontradas
- **CORS configurado**: Listo para consumir desde frontend React
- **Modelos ML con ONNX**:
  - KNN para predicciÃ³n de churn
  - RegresiÃ³n LogÃ­stica para predicciÃ³n de churn
  - K-Means para segmentaciÃ³n de clientes de tarjeta de crÃ©dito

## ğŸ“ Estructura del Proyecto

```
ml_server/
â”œâ”€â”€ models/                  # Coloca tus modelos ONNX aquÃ­
â”‚   â”œâ”€â”€ churn_knn.onnx
â”‚   â”œâ”€â”€ churn_logreg.onnx
â”‚   â””â”€â”€ credit_kmeans.onnx
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.ts              # ConfiguraciÃ³n de Express
â”‚   â”œâ”€â”€ server.ts            # Arranque del servidor
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ env.ts          # Variables de entorno
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ churn.controller.ts
â”‚   â”‚   â””â”€â”€ credit.controller.ts
â”‚   â”œâ”€â”€ middlewares/
â”‚   â”‚   â”œâ”€â”€ errorHandler.ts
â”‚   â”‚   â”œâ”€â”€ notFoundHandler.ts
â”‚   â”‚   â””â”€â”€ validateRequest.ts
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ types.ts        # Interfaces TypeScript
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ churn.routes.ts
â”‚   â”‚   â””â”€â”€ credit.routes.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ churnKnn.service.ts
â”‚   â”‚   â”œâ”€â”€ churnLogReg.service.ts
â”‚   â”‚   â””â”€â”€ creditKmeans.service.ts
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ onnxLoader.ts   # Cargador de modelos ONNX
â”‚       â””â”€â”€ preprocessing.ts # Preprocesamiento de datos
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ .env                     # Variables de entorno (crear)
```

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Instalar Dependencias

```bash
npm install
```

### 2. Configurar Variables de Entorno

Crea un archivo `.env` en la raÃ­z del proyecto:

```env
PORT=3000
NODE_ENV=development
CORS_ORIGIN=http://localhost:5173

# Rutas a los modelos ONNX (opcional, usa valores por defecto si no se especifican)
CHURN_KNN_MODEL_PATH=models/churn_knn.onnx
CHURN_LOGREG_MODEL_PATH=models/churn_logreg.onnx
CREDIT_KMEANS_MODEL_PATH=models/credit_kmeans.onnx
```

### 3. Colocar Modelos ONNX

Coloca tus modelos ONNX entrenados en la carpeta `models/`:

```
models/
â”œâ”€â”€ churn_knn.onnx
â”œâ”€â”€ churn_logreg.onnx
â””â”€â”€ credit_kmeans.onnx
```

**Nota**: Si no colocas los modelos, el servidor iniciarÃ¡ pero los endpoints devolverÃ¡n error. Ver `MODELOS_ONNX.md` para mÃ¡s detalles sobre el formato de los modelos.

### 4. Iniciar el Servidor

**Modo desarrollo** (con hot-reload):
```bash
npm run dev
```

**Compilar TypeScript**:
```bash
npm run build
```

**Modo producciÃ³n**:
```bash
npm start
```

El servidor estarÃ¡ disponible en `http://localhost:3000` (o el puerto configurado en `.env`).

### 5. Verificar que Funciona

Abre otra terminal y prueba el endpoint de salud:

```bash
curl http://localhost:3000/health
```

DeberÃ­as recibir: `{"status":"ok"}`

## ğŸ“¡ Endpoints

### Health Check
- **GET** `/health`
  - Respuesta: `{ "status": "ok" }`

### Churn - KNN
- **POST** `/api/churn/knn`
  - **Body** (JSON):
  ```json
  {
    "adulto_mayor": 0,
    "meses_como_cliente": 12,
    "cargo_mensual": 75.35,
    "tiene_pareja": "Yes",
    "dependientes": "No",
    "tipo_internet": "Fiber optic",
    "seguridad_en_linea": "No",
    "respaldo_en_linea": "No",
    "proteccion_dispositivo": "No",
    "soporte_tecnico": "No",
    "tipo_contrato": "Month-to-month",
    "facturacion_electronica": "Yes",
    "metodo_pago": "Electronic check"
  }
  ```
  - **Respuesta**:
  ```json
  {
    "model": "knn",
    "prediccion": 1,
    "probabilidad": 0.78,
    "mensaje": "El cliente tiene alta probabilidad de abandonar el servicio."
  }
  ```

### Churn - RegresiÃ³n LogÃ­stica
- **POST** `/api/churn/logreg`
  - **Body**: Mismo formato que `/api/churn/knn`
  - **Respuesta**:
  ```json
  {
    "model": "logistic_regression",
    "prediccion": 0,
    "probabilidad": 0.23,
    "mensaje": "El cliente tiene baja probabilidad de abandonar el servicio."
  }
  ```

### Credit Card - K-Means
- **POST** `/api/credit/kmeans`
  - **Body** (JSON):
  ```json
  {
    "Saldo": 1500.50,
    "Frecuencia_Saldo": 0.85,
    "Compras_Totales": 2000.0,
    "Compras_Contado": 500.0,
    "Compras_Cuotas": 1500.0,
    "Avances_Efectivo": 300.0,
    "Frecuencia_Compras": 0.6,
    "Frec_Compras_Contado": 0.2,
    "Frec_Compras_Cuotas": 0.4,
    "Frec_Avances": 0.1,
    "Transacciones_Avance": 5,
    "Transacciones_Compra": 25,
    "Limite_Credito": 5000.0,
    "Pagos_Realizados": 1200.75,
    "Pago_Minimo": 200.0,
    "Pct_Pago_Completo": 0.1
  }
  ```
  - **Respuesta**:
  ```json
  {
    "model": "kmeans",
    "cluster": 2,
    "segmentacion": {
      "cluster": 2,
      "nombre_segmento": "Cliente con dependencia de adelantos",
      "descripcion": "Cliente con balance medio, uso moderado y ligera dependencia de adelantos en efectivo.",
      "detalles": {
        "riesgo": "medio",
        "tipo_cliente": "rotativo",
        "recomendacion": "Ofrecer plan de consolidaciÃ³n de deuda."
      }
    }
  }
  ```

## âš ï¸ Manejo de Errores

Todos los errores se devuelven en formato JSON:

```json
{
  "error": "VALIDATION_ERROR",
  "message": "El campo 'Saldo' es requerido y debe ser numÃ©rico."
}
```

CÃ³digos de estado HTTP:
- `400`: Error de validaciÃ³n
- `404`: Ruta no encontrada
- `500`: Error interno del servidor

## ğŸ”§ TecnologÃ­as

- **Node.js**: Runtime de JavaScript
- **Express**: Framework web
- **TypeScript**: Superset tipado de JavaScript
- **Zod**: ValidaciÃ³n de esquemas
- **CORS**: Middleware para Cross-Origin Resource Sharing
- **dotenv**: Manejo de variables de entorno
- **onnxruntime-node**: Runtime para ejecutar modelos ONNX

## ğŸ“ Notas Importantes

- **Modelos ONNX requeridos**: Los modelos deben estar en la carpeta `models/` para que los endpoints funcionen
- **Formato de modelos**: Ver `MODELOS_ONNX.md` para detalles sobre el formato esperado de los modelos
- **Preprocesamiento**: Los datos se preprocesan automÃ¡ticamente antes de pasarlos a los modelos
- **CORS**: Configurado para permitir peticiones desde `http://localhost:5173` (React por defecto)

## ğŸ§ª Pruebas

### Con curl

**Churn KNN**:
```bash
curl -X POST http://localhost:3000/api/churn/knn \
  -H "Content-Type: application/json" \
  -d '{
    "adulto_mayor": 0,
    "meses_como_cliente": 12,
    "cargo_mensual": 75.35,
    "tiene_pareja": "Yes",
    "dependientes": "No",
    "tipo_internet": "Fiber optic",
    "seguridad_en_linea": "No",
    "respaldo_en_linea": "No",
    "proteccion_dispositivo": "No",
    "soporte_tecnico": "No",
    "tipo_contrato": "Month-to-month",
    "facturacion_electronica": "Yes",
    "metodo_pago": "Electronic check"
  }'
```

**Credit K-Means**:
```bash
curl -X POST http://localhost:3000/api/credit/kmeans \
  -H "Content-Type: application/json" \
  -d '{
    "Saldo": 1500.50,
    "Frecuencia_Saldo": 0.85,
    "Compras_Totales": 2000.0,
    "Compras_Contado": 500.0,
    "Compras_Cuotas": 1500.0,
    "Avances_Efectivo": 300.0,
    "Frecuencia_Compras": 0.6,
    "Frec_Compras_Contado": 0.2,
    "Frec_Compras_Cuotas": 0.4,
    "Frec_Avances": 0.1,
    "Transacciones_Avance": 5,
    "Transacciones_Compra": 25,
    "Limite_Credito": 5000.0,
    "Pagos_Realizados": 1200.75,
    "Pago_Minimo": 200.0,
    "Pct_Pago_Completo": 0.1
  }'
```

### Otras herramientas

TambiÃ©n puedes probar con:
- **Postman**
- **Thunder Client** (VS Code)
- **Frontend React** (desde `http://localhost:5173`)

## ğŸ“š DocumentaciÃ³n Adicional

- **`MODELOS_ONNX.md`**: GuÃ­a detallada sobre cÃ³mo preparar y usar tus modelos ONNX
- **`package.json`**: Scripts disponibles y dependencias

## ğŸ› SoluciÃ³n de Problemas

### El servidor no inicia
- Verifica que todas las dependencias estÃ©n instaladas: `npm install`
- Verifica que el puerto 3000 no estÃ© en uso
- Revisa los logs en la consola para ver errores especÃ­ficos

### Los modelos no se cargan
- Verifica que los archivos `.onnx` estÃ©n en la carpeta `models/`
- Verifica las rutas en `.env` si las personalizaste
- Revisa la consola del servidor para mensajes de error

### Errores de validaciÃ³n
- Verifica que todos los campos requeridos estÃ©n presentes
- Verifica que los tipos de datos sean correctos (nÃºmeros, strings, etc.)
- Revisa el formato esperado en la secciÃ³n de Endpoints

Para mÃ¡s detalles sobre problemas con modelos ONNX, consulta `MODELOS_ONNX.md`.

